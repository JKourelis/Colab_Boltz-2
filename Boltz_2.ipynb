{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JKourelis/Colab_Boltz-2/blob/main/Boltz_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqNojEcK_HM1"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/jwohlwend/boltz/main/docs/boltz2_title.png\" height=\"200\" align=\"right\" style=\"height:240px\">\n",
        "\n",
        "## Boltz-2: Democratizing Biomolecular Interaction Modeling\n",
        "\n",
        "Easy to use protein structure and binding affinity prediction using [Boltz-2](https://doi.org/10.1101/2025.06.14.659707). Boltz-2 is a biomolecular foundation model that jointly models complex structures and binding affinities, approaching [AlphaFold3](https://www.nature.com/articles/s41586-024-07487-w) accuracy while running 1000x faster than physics-based methods.\n",
        "\n",
        "**Key Features:**\n",
        "- **Structure Prediction**: Protein, DNA, RNA, and ligand complexes with AlphaFold3-level accuracy\n",
        "- **Binding Affinity**: First deep learning model to approach FEP accuracy for drug discovery\n",
        "- **Open Source**: MIT license for academic and commercial use\n",
        "- **Fast**: 1000x faster than traditional physics-based methods\n",
        "\n",
        "**Usage Options:**\n",
        "1. **Manual Input**: Enter sequences directly in the configuration boxes below\n",
        "2. **FASTA Upload**: Upload FASTA files for batch processing\n",
        "\n",
        "**Repository:**\n",
        "- [Boltz-2 Colab Repository](https://github.com/JKourelis/Colab_Boltz-2)\n",
        "\n",
        "**Citations:**\n",
        "\n",
        "[Wohlwend J, Corso G, Passaro S, et al. Boltz-1: Democratizing Biomolecular Interaction Modeling. *bioRxiv*, 2024](https://doi.org/10.1101/2024.11.19.624167)\n",
        "\n",
        "[Passaro S, Corso G, Wohlwend J, et al. Boltz-2: Towards Accurate and Efficient Binding Affinity Prediction. *bioRxiv*, 2025](https://doi.org/10.1101/2025.06.14.659707)\n",
        "\n",
        "If using automatic MSA generation: [Mirdita M, Sch√ºtze K, Moriwaki Y, et al. ColabFold: making protein folding accessible to all. *Nature Methods*, 2022](https://doi.org/10.1038/s41592-022-01488-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7Lo35v692ER",
        "outputId": "50eab2eb-8875-4a75-ba98-27bca0d08001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 2: PACKAGE INSTALLATION\n",
            "============================================================\n",
            "‚úÖ Permanent conflict prevention installed\n",
            "   ‚úÖ Cleared 105 cached modules\n",
            "\n",
            "============================================================\n",
            "INSTALLING BOLTZ-2\n",
            "============================================================\n",
            "\n",
            "‚úÖ Detected CUDA 12.4\n",
            "üì¶ Will install PyTorch 2.6.0 (cu124)\n",
            "\n",
            "[Uninstalling conflicting packages]\n",
            "OK\n",
            "[Installing numpy==1.26.4]\n",
            "OK\n",
            "‚úÖ NumPy 1.26.4 verified\n",
            "[Installing pandas and scipy]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<timed exec>:141: UserWarning: The NumPy module was reloaded (imported a second time). This can in some cases result in small but subtle issues and is discouraged.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK\n",
            "[Installing PyTorch 2.6.0 (cu124)]\n",
            "OK\n",
            "[Installing cuEquivariance (cuequivariance-ops-torch-cu12)]\n",
            "OK\n",
            "[Installing lightning stack]\n",
            "OK\n",
            "[Installing boltz]\n",
            "OK\n",
            "[Testing boltz]\n",
            "OK\n",
            "\n",
            "============================================================\n",
            "CUEQUIVARIANCE KERNEL PREFLIGHT TEST\n",
            "============================================================\n",
            "‚úÖ PyTorch: 2.6.0+cu124\n",
            "‚úÖ CUDA available: True\n",
            "‚úÖ CUDA version: 12.4\n",
            "‚úÖ GPU: NVIDIA A100-SXM4-40GB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Error while loading libcue_ops.so: /usr/local/lib/python3.12/dist-packages/cuequivariance_ops/lib/libcue_ops.so: undefined symbol: cublasGemmGroupedBatchedEx, version libcublas.so.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ cuequivariance-torch installed\n",
            "‚ö†Ô∏è  cuequivariance-ops-torch-cu12 not found: libcue_ops.so: cannot open shared object file: No such file or directory\n",
            "\n",
            "‚ùå KERNEL TEST FAILED\n",
            "   cuEquivariance kernels are NOT available\n",
            "   Will run Boltz-2 WITH --no_kernels flag\n",
            "   Performance penalty: ~12 seconds per prediction\n",
            "\n",
            "üîß Flag stored: use_no_kernels = True\n",
            "\n",
            "============================================================\n",
            "INSTALLED PACKAGE VERSIONS\n",
            "============================================================\n",
            "\n",
            "üìã Core packages:\n",
            "   numpy==1.26.4\n",
            "   pandas==2.3.3\n",
            "   scipy==1.13.1\n",
            "   torch==2.6.0+cu124\n",
            "   torchvision==0.21.0+cu124\n",
            "   torchaudio==2.6.0+cu124\n",
            "   pytorch-lightning==2.5.0\n",
            "   torchmetrics==1.4.0\n",
            "   boltz==2.2.1\n",
            "   cuequivariance-torch==0.7.0\n",
            "   cuequivariance-ops-torch-cu12==0.7.0\n",
            "\n",
            "üìÑ Saving complete requirements.txt...\n",
            "   ‚úÖ Saved to: /content/requirements_boltz.txt\n",
            "\n",
            "============================================================\n",
            "‚úÖ BOLTZ-2 INSTALLATION COMPLETE\n",
            "============================================================\n",
            "Next: Configure your sequences in Cell 2\n",
            "CPU times: user 3.83 s, sys: 349 ms, total: 4.18 s\n",
            "Wall time: 1min 57s\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 1: Install Boltz-2 with cuEquivariance Kernel Test\n",
        "%%time\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Restart marker to handle Colab Feb 2025 NumPy issue\n",
        "restart_marker = \"/content/.boltz_numpy_restart\"\n",
        "is_post_restart = os.path.exists(restart_marker)\n",
        "\n",
        "def run_cmd(cmd, desc):\n",
        "    \"\"\"Execute command with output suppression unless error\"\"\"\n",
        "    print(f\"[{desc}]\")\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(f\"FAILED: {result.stderr[:300]}\")\n",
        "        return False\n",
        "    print(\"OK\")\n",
        "    return True\n",
        "\n",
        "def get_cuda_version():\n",
        "    \"\"\"Detect CUDA version from nvidia-smi\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        if result.returncode == 0:\n",
        "            match = re.search(r'CUDA Version: (\\d+\\.\\d+)', result.stdout)\n",
        "            if match:\n",
        "                version = match.group(1)\n",
        "                major = int(version.split('.')[0])\n",
        "                minor = int(version.split('.')[1])\n",
        "                return major, minor, version\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not detect CUDA version: {e}\")\n",
        "    return None, None, None\n",
        "\n",
        "def test_cuequivariance_kernels():\n",
        "    \"\"\"Test if cuEquivariance triangle kernels are available\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"CUEQUIVARIANCE KERNEL PREFLIGHT TEST\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    try:\n",
        "        import torch\n",
        "        print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
        "        print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
        "            print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå PyTorch check failed: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Test cuequivariance-torch import\n",
        "    try:\n",
        "        import cuequivariance_torch\n",
        "        print(f\"‚úÖ cuequivariance-torch installed\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ö†Ô∏è  cuequivariance-torch not found: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Test cuequivariance-ops-torch-cu12 import\n",
        "    try:\n",
        "        import cuequivariance_ops_torch\n",
        "        print(f\"‚úÖ cuequivariance-ops-torch-cu12 installed\")\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ö†Ô∏è  cuequivariance-ops-torch-cu12 not found: {e}\")\n",
        "        return False\n",
        "\n",
        "    # CRITICAL TEST: triangle_multiplicative_update\n",
        "    try:\n",
        "        from cuequivariance_ops_torch.triangle import triangle_multiplicative_update\n",
        "        print(f\"‚úÖ triangle_multiplicative_update import: SUCCESS\")\n",
        "\n",
        "        if callable(triangle_multiplicative_update):\n",
        "            print(f\"‚úÖ triangle_multiplicative_update is callable\")\n",
        "        else:\n",
        "            print(f\"‚ùå triangle_multiplicative_update exists but is not callable\")\n",
        "            return False\n",
        "\n",
        "    except ImportError as e:\n",
        "        print(f\"‚ùå triangle_multiplicative_update import FAILED: {e}\")\n",
        "        print(f\"   This error requires --no_kernels flag\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error testing triangle kernels: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "def install_boltz():\n",
        "    \"\"\"Install Boltz-2 and dependencies with NumPy compatibility fix\"\"\"\n",
        "\n",
        "    # Detect CUDA version\n",
        "    cuda_major, cuda_minor, cuda_version = get_cuda_version()\n",
        "\n",
        "    if cuda_major is None:\n",
        "        print(\"‚ùå Could not detect CUDA version\")\n",
        "        return False\n",
        "\n",
        "    print(f\"‚úÖ Detected CUDA {cuda_version}\")\n",
        "\n",
        "    # Determine PyTorch version and index URL based on CUDA\n",
        "    if cuda_major == 12:\n",
        "        if cuda_minor >= 4:\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            pytorch_cuda = \"cu124\"\n",
        "            index_url = \"https://download.pytorch.org/whl/cu124\"\n",
        "        else:\n",
        "            pytorch_version = \"2.6.0\"\n",
        "            pytorch_cuda = \"cu121\"\n",
        "            index_url = \"https://download.pytorch.org/whl/cu121\"\n",
        "    elif cuda_major == 11:\n",
        "        pytorch_version = \"2.6.0\"\n",
        "        pytorch_cuda = \"cu118\"\n",
        "        index_url = \"https://download.pytorch.org/whl/cu118\"\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Unsupported CUDA version: {cuda_version}\")\n",
        "        print(\"   Attempting with CUDA 12.4 packages\")\n",
        "        pytorch_version = \"2.6.0\"\n",
        "        pytorch_cuda = \"cu124\"\n",
        "        index_url = \"https://download.pytorch.org/whl/cu124\"\n",
        "\n",
        "    print(f\"üì¶ Will install PyTorch {pytorch_version} ({pytorch_cuda})\")\n",
        "\n",
        "    # Nuclear cleanup\n",
        "    print(\"\\n[Uninstalling conflicting packages]\")\n",
        "    subprocess.run(\n",
        "        f\"{sys.executable} -m pip uninstall -y numpy pandas scipy torch torchvision torchaudio pytorch-lightning torchmetrics boltz\",\n",
        "        shell=True, capture_output=True\n",
        "    )\n",
        "    print(\"OK\")\n",
        "\n",
        "    # Install NumPy 1.26.4 first\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q numpy==1.26.4\",\n",
        "        \"Installing numpy==1.26.4\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Verify NumPy version\n",
        "    try:\n",
        "        import numpy as np\n",
        "        if not np.__version__.startswith('1.26'):\n",
        "            print(f\"‚ùå NumPy version mismatch: {np.__version__}\")\n",
        "            return False\n",
        "        print(f\"‚úÖ NumPy {np.__version__} verified\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå NumPy verification failed: {e}\")\n",
        "        return False\n",
        "\n",
        "    # Install compatible pandas and scipy\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q pandas scipy\",\n",
        "        \"Installing pandas and scipy\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Install PyTorch with correct CUDA version\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q torch=={pytorch_version}+{pytorch_cuda} torchvision torchaudio --index-url {index_url}\",\n",
        "        f\"Installing PyTorch {pytorch_version} ({pytorch_cuda})\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Install cuEquivariance with correct CUDA version\n",
        "    if cuda_major == 12:\n",
        "        cuequiv_pkg = \"cuequivariance-ops-torch-cu12\"\n",
        "    elif cuda_major == 11:\n",
        "        cuequiv_pkg = \"cuequivariance-ops-torch-cu11\"\n",
        "    else:\n",
        "        cuequiv_pkg = \"cuequivariance-ops-torch-cu12\"\n",
        "\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q cuequivariance-torch {cuequiv_pkg}\",\n",
        "        f\"Installing cuEquivariance ({cuequiv_pkg})\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Install Lightning stack\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q pytorch-lightning==2.4.0 torchmetrics==1.4.0\",\n",
        "        \"Installing lightning stack\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Install boltz\n",
        "    if not run_cmd(\n",
        "        f\"{sys.executable} -m pip install -q boltz\",\n",
        "        \"Installing boltz\"\n",
        "    ):\n",
        "        return False\n",
        "\n",
        "    # Test installation\n",
        "    print(\"[Testing boltz]\")\n",
        "    test_result = subprocess.run([\"boltz\", \"--help\"], capture_output=True, text=True, timeout=30)\n",
        "\n",
        "    if test_result.returncode != 0:\n",
        "        print(\"FAILED:\")\n",
        "        print(test_result.stderr)\n",
        "        return False\n",
        "\n",
        "    print(\"OK\")\n",
        "\n",
        "    # Create ready marker\n",
        "    with open(\"/content/BOLTZ_READY\", \"w\") as f:\n",
        "        f.write(\"Ready\")\n",
        "\n",
        "    return True, pytorch_version, pytorch_cuda, cuda_version\n",
        "\n",
        "# MAIN EXECUTION\n",
        "if not is_post_restart:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PHASE 1: ENVIRONMENT SETUP (requires restart)\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"\\n‚ö†Ô∏è  Colab Feb 2025 pre-loads NumPy 2.0, but Boltz-2 requires 1.26\")\n",
        "    print(\"   This will take ~10 seconds for one-time restart\\n\")\n",
        "\n",
        "    # Create restart marker\n",
        "    with open(restart_marker, \"w\") as f:\n",
        "        f.write(\"pre-restart\")\n",
        "\n",
        "    print(\"üîÑ Restarting Python environment...\")\n",
        "    import time\n",
        "    time.sleep(2)\n",
        "    os.kill(os.getpid(), 9)\n",
        "\n",
        "else:\n",
        "    print(\"=\" * 60)\n",
        "    print(\"PHASE 2: PACKAGE INSTALLATION\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # sitecustomize.py prevention\n",
        "    python_version = f\"{sys.version_info.major}.{sys.version_info.minor}\"\n",
        "    sitecustomize_path = f\"/usr/local/lib/python{python_version}/dist-packages/sitecustomize.py\"\n",
        "\n",
        "    sitecustomize_content = \"\"\"import sys\n",
        "if '/env/python' in sys.path:\n",
        "    sys.path.remove('/env/python')\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(sitecustomize_path, \"w\") as f:\n",
        "            f.write(sitecustomize_content)\n",
        "        print(\"‚úÖ Permanent conflict prevention installed\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Could not install sitecustomize.py: {e}\")\n",
        "\n",
        "    # Current kernel cleanup\n",
        "    if '/env/python' in sys.path:\n",
        "        sys.path.remove('/env/python')\n",
        "\n",
        "    # Clear cached imports\n",
        "    modules_to_clear = [key for key in list(sys.modules.keys())\n",
        "                       if key.startswith(('numpy', 'pandas', 'np', 'pd'))]\n",
        "    for mod in modules_to_clear:\n",
        "        del sys.modules[mod]\n",
        "\n",
        "    if modules_to_clear:\n",
        "        print(f\"   ‚úÖ Cleared {len(modules_to_clear)} cached modules\")\n",
        "\n",
        "    # Install Boltz (verification happens inside this function)\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INSTALLING BOLTZ-2\")\n",
        "    print(\"=\" * 60 + \"\\n\")\n",
        "\n",
        "    result = install_boltz()\n",
        "    if not result:\n",
        "        print(\"\\n‚ùå Installation failed\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    success, pytorch_version, pytorch_cuda, cuda_version = result\n",
        "\n",
        "    # CUEQUIVARIANCE KERNEL TEST\n",
        "    kernels_available = test_cuequivariance_kernels()\n",
        "\n",
        "    if kernels_available:\n",
        "        print(\"\\n‚úÖ KERNEL TEST PASSED\")\n",
        "        print(\"   cuEquivariance kernels are available\")\n",
        "        print(\"   Will run Boltz-2 WITHOUT --no_kernels flag\")\n",
        "        use_no_kernels = False\n",
        "    else:\n",
        "        print(\"\\n‚ùå KERNEL TEST FAILED\")\n",
        "        print(\"   cuEquivariance kernels are NOT available\")\n",
        "        print(\"   Will run Boltz-2 WITH --no_kernels flag\")\n",
        "        print(\"   Performance penalty: ~12 seconds per prediction\")\n",
        "        use_no_kernels = True\n",
        "\n",
        "    # Store result for execution cell\n",
        "    if 'global_settings' not in globals():\n",
        "        global_settings = {}\n",
        "    global_settings['use_no_kernels'] = use_no_kernels\n",
        "    global_settings['kernels_tested'] = True\n",
        "\n",
        "    print(f\"\\nüîß Flag stored: use_no_kernels = {use_no_kernels}\")\n",
        "\n",
        "    # Show installed versions\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"INSTALLED PACKAGE VERSIONS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    result = subprocess.run(\n",
        "        [sys.executable, \"-m\", \"pip\", \"list\", \"--format=freeze\"],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "\n",
        "    all_packages = result.stdout.strip().split('\\n')\n",
        "    relevant = [\n",
        "        'numpy', 'pandas', 'scipy',\n",
        "        'torch', 'torchvision', 'torchaudio',\n",
        "        'pytorch-lightning', 'torchmetrics',\n",
        "        'boltz', 'cuequivariance-torch',\n",
        "        'cuequivariance-ops-torch-cu11',\n",
        "        'cuequivariance-ops-torch-cu12'\n",
        "    ]\n",
        "\n",
        "    print(\"\\nüìã Core packages:\")\n",
        "    for pkg in relevant:\n",
        "        for line in all_packages:\n",
        "            if line.lower().startswith(pkg.lower() + '=='):\n",
        "                print(f\"   {line}\")\n",
        "                break\n",
        "        else:\n",
        "            for line in all_packages:\n",
        "                if pkg.lower().replace('-', '_') in line.lower():\n",
        "                    print(f\"   {line}\")\n",
        "                    break\n",
        "\n",
        "    # Save complete requirements.txt\n",
        "    print(\"\\nüìÑ Saving complete requirements.txt...\")\n",
        "    with open(\"/content/requirements_boltz.txt\", \"w\") as f:\n",
        "        f.write(f\"# Boltz-2 Installation - CUDA {cuda_version}\\n\")\n",
        "        f.write(f\"# PyTorch {pytorch_version} ({pytorch_cuda})\\n\\n\")\n",
        "        f.write(result.stdout)\n",
        "    print(\"   ‚úÖ Saved to: /content/requirements_boltz.txt\")\n",
        "\n",
        "    # Cleanup and mark ready\n",
        "    os.remove(restart_marker)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ BOLTZ-2 INSTALLATION COMPLETE\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Next: Configure your sequences in Cell 2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcbddZPH52WA",
        "outputId": "a9ecbec5-8a6c-4fd1-b663-68e0194a3f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚òÅÔ∏è  Setting up Google Drive...\n",
            "Mounted at /content/gdrive\n",
            "‚úÖ Google Drive connected\n",
            "‚úÖ Manual sequences configured:\n",
            "üè∑Ô∏è Job name: Cf4AVR4-single_791fc\n",
            "  Cf4: protein, 1 copies, chains: ['Cf4']\n",
            "    Content: SSLPHLCPEDQALALLEFKNMFTVNPNASDYCYDRRTLSWNKSTSCCSWD...\n",
            "  AVR4: protein, 1 copies, chains: ['AVR4']\n",
            "    Content: PCKPQEVIDTKCMGPKDCLYPNPDSCTTYIQCVPLDEVGNAKPVVKPCPK...\n",
            "\n",
            "üìä Total sequences: 2\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 3: Manual Input Configuration (Skip if using FASTA Upload)\n",
        "#@markdown Only run this cell if you selected \"Manual Input\" above\n",
        "\n",
        "# Job configuration\n",
        "jobname = '' #@param {type:\"string\"}\n",
        "#@markdown - Job name for output files\n",
        "\n",
        "# Google Drive setup\n",
        "setup_google_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown - Setup Google Drive for automatic result upload\n",
        "gdrive_folder_name = \"Boltz2_Predictions\" #@param {type:\"string\"}\n",
        "#@markdown - Google Drive folder name\n",
        "\n",
        "# Sequence inputs\n",
        "seq1_name = 'A' #@param {type:\"string\"}\n",
        "seq1_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq1_content = '' #@param {type:\"string\"}\n",
        "seq1_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq2_name = 'B' #@param {type:\"string\"}\n",
        "seq2_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq2_content = '' #@param {type:\"string\"}\n",
        "seq2_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq3_name = 'C' #@param {type:\"string\"}\n",
        "seq3_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq3_content = '' #@param {type:\"string\"}\n",
        "seq3_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq4_name = 'D' #@param {type:\"string\"}\n",
        "seq4_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq4_content = '' #@param {type:\"string\"}\n",
        "seq4_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq5_name = 'E' #@param {type:\"string\"}\n",
        "seq5_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq5_content = '' #@param {type:\"string\"}\n",
        "seq5_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq6_name = 'F' #@param {type:\"string\"}\n",
        "seq6_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq6_content = '' #@param {type:\"string\"}\n",
        "seq6_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq7_name = 'G' #@param {type:\"string\"}\n",
        "seq7_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq7_content = '' #@param {type:\"string\"}\n",
        "seq7_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq8_name = 'H' #@param {type:\"string\"}\n",
        "seq8_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq8_content = '' #@param {type:\"string\"}\n",
        "seq8_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq9_name = 'I' #@param {type:\"string\"}\n",
        "seq9_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq9_content = '' #@param {type:\"string\"}\n",
        "seq9_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "seq10_name = 'J' #@param {type:\"string\"}\n",
        "seq10_type = \"protein\" #@param [\"protein\", \"dna\", \"rna\", \"smiles\", \"ccd\"]\n",
        "seq10_content = '' #@param {type:\"string\"}\n",
        "seq10_copies = 1 #@param {type:\"integer\"}\n",
        "\n",
        "# Check if this cell should run\n",
        "if 'global_settings' not in globals():\n",
        "    print(\"‚ö†Ô∏è  Please run the 'Choose Input Method' cell first\")\n",
        "elif global_settings['input_method'] != \"Manual Input\":\n",
        "    print(\"‚è≠Ô∏è  Skipping manual input (FASTA Upload selected)\")\n",
        "else:\n",
        "    # Setup Google Drive if requested\n",
        "    drive = None\n",
        "    if setup_google_drive:\n",
        "        try:\n",
        "            from pydrive2.drive import GoogleDrive\n",
        "            from pydrive2.auth import GoogleAuth\n",
        "            from google.colab import auth\n",
        "            from oauth2client.client import GoogleCredentials\n",
        "            from google.colab import files\n",
        "\n",
        "            print(\"Setting up Google Drive...\")\n",
        "            auth.authenticate_user()\n",
        "            gauth = GoogleAuth()\n",
        "            gauth.credentials = GoogleCredentials.get_application_default()\n",
        "            drive = GoogleDrive(gauth)\n",
        "            print(\"‚úÖ Google Drive connected successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Google Drive setup failed: {e}\")\n",
        "            drive = None\n",
        "\n",
        "    # Process sequences - ALWAYS use A, B, C, etc. for MSA compatibility\n",
        "    sequences = []\n",
        "    all_sequences = [\n",
        "        (seq1_name, seq1_type, seq1_content, seq1_copies),\n",
        "        (seq2_name, seq2_type, seq2_content, seq2_copies),\n",
        "        (seq3_name, seq3_type, seq3_content, seq3_copies),\n",
        "        (seq4_name, seq4_type, seq4_content, seq4_copies),\n",
        "        (seq5_name, seq5_type, seq5_content, seq5_copies),\n",
        "        (seq6_name, seq6_type, seq6_content, seq6_copies),\n",
        "        (seq7_name, seq7_type, seq7_content, seq7_copies),\n",
        "        (seq8_name, seq8_type, seq8_content, seq8_copies),\n",
        "        (seq9_name, seq9_type, seq9_content, seq9_copies),\n",
        "        (seq10_name, seq10_type, seq10_content, seq10_copies)\n",
        "    ]\n",
        "\n",
        "    # Generate sequential letter IDs for MSA compatibility (5-char limit)\n",
        "    # CRITICAL: Each copy gets a DIFFERENT letter (A, B, C...)\n",
        "    # YAML generation groups identical sequences for MSA optimization\n",
        "    letter_index = 0\n",
        "    alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "\n",
        "    for name, seq_type, content, copies in all_sequences:\n",
        "        if content.strip():  # Only process non-empty sequences\n",
        "            chain_ids = []\n",
        "\n",
        "            # Each copy gets its own letter - EXACT CSV processor behavior\n",
        "            for copy_num in range(copies):\n",
        "                if letter_index < len(alphabet):\n",
        "                    chain_ids.append(alphabet[letter_index])\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è  Warning: Exceeded 26 chains. Using extended notation.\")\n",
        "                    chain_ids.append(f\"Z{letter_index - 25}\")\n",
        "\n",
        "                letter_index += 1  # Increment for EACH copy\n",
        "\n",
        "            sequences.append({\n",
        "                'name': name,  # Preserve user name for display\n",
        "                'type': seq_type,\n",
        "                'content': content.strip(),\n",
        "                'copies': copies,\n",
        "                'chain_ids': chain_ids  # Each copy has unique ID: A, B for 2 copies\n",
        "            })\n",
        "\n",
        "    # Generate jobname hash\n",
        "    if sequences:\n",
        "        sequence_string = \"\".join([seq['content'] for seq in sequences])\n",
        "        final_jobname = add_hash(jobname.replace(' ', '_'), sequence_string)\n",
        "\n",
        "        # Update global settings\n",
        "        global_settings.update({\n",
        "            'sequences': sequences,\n",
        "            'drive': drive,\n",
        "            'gdrive_folder_name': gdrive_folder_name,\n",
        "            'final_jobname': final_jobname\n",
        "        })\n",
        "\n",
        "        print(\"‚úÖ Manual sequences configured:\")\n",
        "        print(f\"üìÅ Job name: {final_jobname}\")\n",
        "        for seq in sequences:\n",
        "            print(f\"  {seq['name']}: {seq['type']}, {seq['copies']} copies, chains: {seq['chain_ids']}\")\n",
        "            print(f\"    Content: {seq['content'][:50]}{'...' if len(seq['content']) > 50 else ''}\")\n",
        "    else:\n",
        "        print(\"‚ùå No sequences provided\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnrh_B6Y92ph",
        "outputId": "7fe3e81b-f749-44dd-b128-b90112db41ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MSA configuration set:\n",
            "  Mode: mmseqs2_uniref_env\n",
            "  Pairing strategy: greedy\n",
            "  Use MSA server: True\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 3: MSA Configuration\n",
        "msa_mode = \"mmseqs2_uniref_env\" #@param [\"mmseqs2_uniref_env\", \"mmseqs2_uniref\",\"single_sequence\",\"custom\"]\n",
        "#@markdown - MSA generation method. mmseqs2 modes use the ColabFold server\n",
        "\n",
        "msa_pairing_strategy = \"greedy\" #@param [\"greedy\", \"complete\"]\n",
        "#@markdown - `greedy` = pair any taxonomically matching subsets, `complete` = all sequences must match\n",
        "\n",
        "# Check if global_settings exists\n",
        "if 'global_settings' not in globals():\n",
        "    print(\"‚ö†Ô∏è  Please run the 'Choose Input Method' cell first\")\n",
        "else:\n",
        "    # Configure MSA settings based on mode\n",
        "    if \"mmseqs2\" in msa_mode:\n",
        "        use_msa_server = True\n",
        "        msa_server_url = \"https://api.colabfold.com\"\n",
        "    else:\n",
        "        use_msa_server = False\n",
        "        msa_server_url = None\n",
        "\n",
        "    # Handle custom MSA upload if selected\n",
        "    if msa_mode == \"custom\":\n",
        "        print(\"Upload your custom MSA file (A3M format):\")\n",
        "        from google.colab import files\n",
        "        custom_msa_dict = files.upload()\n",
        "        if custom_msa_dict:\n",
        "            custom_msa_file = list(custom_msa_dict.keys())[0]\n",
        "            print(f\"Custom MSA uploaded: {custom_msa_file}\")\n",
        "        else:\n",
        "            print(\"No custom MSA uploaded, switching to single_sequence mode\")\n",
        "            msa_mode = \"single_sequence\"\n",
        "            use_msa_server = False\n",
        "\n",
        "    # Store MSA settings in global_settings\n",
        "    global_settings.update({\n",
        "        'msa_mode': msa_mode,\n",
        "        'msa_pairing_strategy': msa_pairing_strategy,\n",
        "        'use_msa_server': use_msa_server,\n",
        "        'msa_server_url': msa_server_url\n",
        "    })\n",
        "\n",
        "    print(f\"‚úÖ MSA configuration set:\")\n",
        "    print(f\"  Mode: {msa_mode}\")\n",
        "    print(f\"  Pairing strategy: {msa_pairing_strategy}\")\n",
        "    print(f\"  Use MSA server: {use_msa_server}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3am6YdJ92zA",
        "outputId": "41606903-7a6f-4a70-8d34-c17ca3820e17",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Advanced settings configured:\n",
            "  Recycling steps: 6\n",
            "  Sampling steps: 200\n",
            "  Diffusion samples: 5\n",
            "  Predict affinity: False\n",
            "  Output format: mmcif\n",
            "  Use potentials: True\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 4: Advanced Prediction Settings\n",
        "# Structure Prediction Settings\n",
        "recycling_steps = 6 #@param {type:\"integer\"}\n",
        "#@markdown - **Iterative refinement passes**: Each cycle refines the structure using updated predictions. Higher values improve local geometry and confidence scores. **Time**: ~linear scaling (3 steps = 3x base time). **VRAM**: +20-30% per additional step for intermediate states.\n",
        "\n",
        "sampling_steps = 200 #@param {type:\"integer\"}\n",
        "#@markdown - **Diffusion denoising iterations**: Controls how many steps the diffusion model takes to generate structures from noise. More steps = smoother, higher quality structures. **Time**: Linear scaling (50 steps = 4x faster than 200). **VRAM**: +10-15% for intermediate diffusion states.\n",
        "\n",
        "diffusion_samples = 5 #@param {type:\"integer\"}\n",
        "#@markdown - **Independent structure predictions**: Number of different structures generated per input. More samples increase diversity and reliability of results. **Time**: Linear scaling (5 samples = 5x base time). **VRAM**: Depends on max_parallel_samples setting.\n",
        "\n",
        "max_parallel_samples = 5 #@param {type:\"integer\"}\n",
        "#@markdown - **GPU memory management**: How many diffusion samples are processed simultaneously. Critical for large complexes - each parallel sample requires full model memory allocation. **Time**: Minimal impact on total time. **VRAM**: ~Linear scaling (2 parallel = ~2x memory, 5 parallel = ~5x memory).\n",
        "\n",
        "step_scale = 1.638 #@param {type:\"number\"}\n",
        "#@markdown - **Sampling temperature**: Controls randomness in structure generation. Higher values increase diversity but may reduce quality. 1.638 is optimized default. **Time**: No impact. **VRAM**: No impact.\n",
        "\n",
        "# Affinity Prediction Settings\n",
        "predict_affinity = False #@param {type:\"boolean\"}\n",
        "#@markdown - **Binding strength prediction**: Runs additional affinity model to predict binding strength (Kd/Ki values). Most reliable for protein-small molecule complexes. **Time**: +50-100% total time. **VRAM**: +40-60% for affinity model loading.\n",
        "\n",
        "affinity_mw_correction = False #@param {type:\"boolean\"}\n",
        "#@markdown - **Molecular weight adjustment**: Applies size-based corrections to affinity predictions. Only affects affinity calculation, not structure. **Time**: Minimal impact. **VRAM**: No impact.\n",
        "\n",
        "sampling_steps_affinity = 200 #@param {type:\"integer\"}\n",
        "#@markdown - **Affinity model diffusion steps**: Controls quality of affinity predictions. Similar to sampling_steps but for the affinity model. **Time**: Linear scaling within affinity prediction. **VRAM**: +5-10% for affinity diffusion states.\n",
        "\n",
        "diffusion_samples_affinity = 5 #@param {type:\"integer\"}\n",
        "#@markdown - **Affinity prediction ensemble size**: Number of independent affinity predictions to average for final binding strength. More samples = more reliable Kd estimates. **Time**: Linear scaling for affinity portion. **VRAM**: Minimal additional impact.\n",
        "\n",
        "# Output and Optimization Settings\n",
        "output_format = \"mmcif\" #@param [\"mmcif\", \"pdb\"]\n",
        "#@markdown - **Structure file format**: mmCIF supports more metadata and modern features, PDB is more widely compatible. Both contain same structural information. **Time**: No impact. **VRAM**: No impact.\n",
        "\n",
        "write_full_pae = True #@param {type:\"boolean\"}\n",
        "#@markdown - **Save Predicted Aligned Error matrix**: Confidence scores between all residue pairs. Essential for assessing interface quality and domain reliability. **Time**: +5-10% for matrix computation and I/O. **VRAM**: +10-20% for large complexes during matrix storage.\n",
        "\n",
        "write_full_pde = False #@param {type:\"boolean\"}\n",
        "#@markdown - **Save Predicted Distance Error matrix**: Distance confidence predictions between residue pairs. Useful for validation and uncertainty quantification. **Time**: +5-10% for matrix computation and I/O. **VRAM**: +10-20% for large complexes during matrix storage.\n",
        "\n",
        "use_potentials = True #@param {type:\"boolean\"}\n",
        "#@markdown - **Inference-time physics optimization**: Applies physics-based energy minimization to improve local geometry and remove clashes. Significantly improves structure quality, especially for interfaces. **Time**: +30-50% total time. **VRAM**: +15-25% for physics calculation buffers.\n",
        "\n",
        "# Check if global_settings exists\n",
        "if 'global_settings' not in globals():\n",
        "    print(\"‚ö†Ô∏è  Please run the 'Choose Input Method' cell first\")\n",
        "else:\n",
        "    # Store advanced settings\n",
        "    advanced_settings = {\n",
        "        'recycling_steps': recycling_steps,\n",
        "        'sampling_steps': sampling_steps,\n",
        "        'diffusion_samples': diffusion_samples,\n",
        "        'max_parallel_samples': max_parallel_samples,\n",
        "        'step_scale': step_scale,\n",
        "        'predict_affinity': predict_affinity,\n",
        "        'affinity_mw_correction': affinity_mw_correction,\n",
        "        'sampling_steps_affinity': sampling_steps_affinity,\n",
        "        'diffusion_samples_affinity': diffusion_samples_affinity,\n",
        "        'output_format': output_format,\n",
        "        'write_full_pae': write_full_pae,\n",
        "        'write_full_pde': write_full_pde,\n",
        "        'use_potentials': use_potentials,\n",
        "        'max_msa_seqs': 8192,\n",
        "        'subsample_msa': False,\n",
        "        'num_subsampled_msa': 1024\n",
        "    }\n",
        "\n",
        "    global_settings.update(advanced_settings)\n",
        "\n",
        "    print(\"‚úÖ Advanced settings configured:\")\n",
        "    print(f\"  Recycling steps: {recycling_steps}\")\n",
        "    print(f\"  Sampling steps: {sampling_steps}\")\n",
        "    print(f\"  Diffusion samples: {diffusion_samples}\")\n",
        "    print(f\"  Predict affinity: {predict_affinity}\")\n",
        "    print(f\"  Output format: {output_format}\")\n",
        "    print(f\"  Use potentials: {use_potentials}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srPcPZupIjUh",
        "outputId": "d75c9961-32b4-47b0-e669-157a763e1290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Residue modifications configured: 0 modifications\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 4.1: Residue Modifications Instructions (Optional)\n",
        "#@markdown Specify residue modifications for amino acid, DNA, or RNA sequences. Each row should define one modification, with values separated by colons (:). The format is:\n",
        "#@markdown\n",
        "#@markdown `SEQ_ID : RESIDUE_INDEX : CCD_CODE`\n",
        "#@markdown\n",
        "#@markdown * **SEQ_ID** ‚Üí The chain ID of the sequence as defined in **Input Sequences**.\n",
        "#@markdown * **RESIDUE_INDEX** ‚Üí The residue position to modify. Use **1** for the first residue.\n",
        "#@markdown * **CCD_CODE** ‚Üí The **Chemical Component Dictionary (CCD) code** of the modification.\n",
        "#@markdown\n",
        "#@markdown **Example Input:**\n",
        "#@markdown ```\n",
        "#@markdown A:102:MLY\n",
        "#@markdown B:1:5MC\n",
        "#@markdown C:26:PSU\n",
        "#@markdown ```\n",
        "#@markdown\n",
        "#@markdown **Notes:**\n",
        "#@markdown * Chain IDs (**SEQ_ID**) must match those in **Input Sequences**.\n",
        "#@markdown * Residue indices start at **1**, not **0**.\n",
        "#@markdown * Use valid **CCD codes** for modifications, use this resource for information on which CCD codes to use for your modification: https://pmc.ncbi.nlm.nih.gov/articles/PMC11394121/\n",
        "\n",
        "residue_modifications = '' #@param {type:\"string\"}\n",
        "#@markdown - Enter residue modifications (one per line, format: CHAIN_ID:RESIDUE_INDEX:CCD_CODE)\n",
        "\n",
        "# Process residue modifications\n",
        "modifications_list = []\n",
        "if residue_modifications.strip():\n",
        "    for line in residue_modifications.strip().split('\\n'):\n",
        "        if line.strip():\n",
        "            parts = line.strip().split(':')\n",
        "            if len(parts) == 3:\n",
        "                chain_id, res_idx, ccd_code = parts\n",
        "                modifications_list.append({\n",
        "                    'chain_id': chain_id.strip(),\n",
        "                    'position': int(res_idx.strip()),\n",
        "                    'ccd': ccd_code.strip()\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Invalid modification format: {line}\")\n",
        "\n",
        "print(f\"Residue modifications configured: {len(modifications_list)} modifications\")\n",
        "for mod in modifications_list:\n",
        "    print(f\"  Chain {mod['chain_id']}, position {mod['position']}: {mod['ccd']}\")\n",
        "\n",
        "if 'global_settings' in globals() and modifications_list:\n",
        "    global_settings['modifications_list'] = modifications_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5cXA7_UImSm",
        "outputId": "f4712f1a-6226-4d50-d9db-e47391f1ab12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No pocket restraints configured\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 4.2: Pocket Restraints Instructions (Optional)\n",
        "#@markdown The **Binder Chain** corresponds to the binder chain, while \"Contact Residues\" specifies residues interacting with it.\n",
        "#@markdown Specify inter-chain pocket restraints to guide Boltz-2 in folding complexes. These restraints define interactions between a binder sequence and residues in other sequences, influencing the folding process.\n",
        "#@markdown Each row should define one pocket restraint, with values separated by colons (:). The format is:\n",
        "#@markdown\n",
        "#@markdown `CONTACT_CHAIN:CONTACT_RES`\n",
        "#@markdown\n",
        "#@markdown * **CONTACT_CHAIN** ‚Üí The chain containing the interacting residue.\n",
        "#@markdown * **CONTACT_RES** ‚Üí The position of the residue on **CONTACT_CHAIN**.\n",
        "#@markdown\n",
        "#@markdown **Example Input:**\n",
        "#@markdown ```\n",
        "#@markdown A:66\n",
        "#@markdown A:78\n",
        "#@markdown B:13\n",
        "#@markdown ```\n",
        "#@markdown\n",
        "#@markdown **Notes:**\n",
        "#@markdown * Chain names match those in **Input Sequences**.\n",
        "#@markdown * Residue numbering starts at 1.\n",
        "#@markdown * The model currently only supports a single binder chain per pocket restraint, but multiple contact residues can be specified across different chains.\n",
        "#@markdown * The chain name of the binder should only be specified if pocket restraints are being used.\n",
        "\n",
        "binder_chain = '' #@param {type:\"string\"}\n",
        "#@markdown - Specify the chain acting as the binder. See above instructions for more details.\n",
        "contact_residues = '' #@param {type:\"string\"}\n",
        "#@markdown - Specify residues interacting with the binder chain. See above instructions for more details.\n",
        "\n",
        "# Process pocket restraints\n",
        "pocket_contacts = []\n",
        "if contact_residues.strip() and binder_chain.strip():\n",
        "    for line in contact_residues.strip().split('\\n'):\n",
        "        if line.strip():\n",
        "            parts = line.strip().split(':')\n",
        "            if len(parts) == 2:\n",
        "                contact_chain, contact_res = parts\n",
        "                pocket_contacts.append({\n",
        "                    'chain_id': contact_chain.strip(),\n",
        "                    'residue': int(contact_res.strip())\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Invalid contact format: {line}\")\n",
        "\n",
        "if binder_chain.strip():\n",
        "    print(f\"Pocket restraints configured:\")\n",
        "    print(f\"  Binder chain: {binder_chain.strip()}\")\n",
        "    print(f\"  Contact residues: {len(pocket_contacts)} contacts\")\n",
        "    for contact in pocket_contacts:\n",
        "        print(f\"    Chain {contact['chain_id']}, residue {contact['residue']}\")\n",
        "else:\n",
        "    print(\"No pocket restraints configured\")\n",
        "\n",
        "if 'global_settings' in globals() and binder_chain.strip():\n",
        "    global_settings['binder_chain'] = binder_chain.strip()\n",
        "    global_settings['pocket_contacts'] = pocket_contacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7rSMomHIq8K",
        "outputId": "2888581e-d3cf-43dd-e739-b555f73023c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covalent restraints configured: 0 bonds\n"
          ]
        }
      ],
      "source": [
        "#@title Cell 4.3: Covalent Restraints Instructions (Optional)\n",
        "#@markdown Specify covalent bonds between atoms to guide Boltz-2 in complex folding. These restraints define fixed interactions between atoms in different sequences, ensuring structural constraints are maintained.\n",
        "#@markdown Each row should define one covalent restraint, with values separated by colons (:). The format is:\n",
        "#@markdown\n",
        "#@markdown `CHAIN_ID1:RES_ID1:ATOM_NAME1:CHAIN_ID2:RES_ID2:ATOM_NAME2`\n",
        "#@markdown\n",
        "#@markdown * **CHAIN_ID1** ‚Üí The chain containing the first atom.\n",
        "#@markdown * **RES_ID1** ‚Üí Residue index on **CHAIN_ID1**.\n",
        "#@markdown * **ATOM_NAME1** ‚Üí Atom name in **RES_ID1**.\n",
        "#@markdown * **CHAIN_ID2** ‚Üí The chain containing the second atom.\n",
        "#@markdown * **RES_ID2** ‚Üí Residue index on **CHAIN_ID2**.\n",
        "#@markdown * **ATOM_NAME2** ‚Üí Atom name in **RES_ID2**.\n",
        "#@markdown\n",
        "#@markdown **Example Input:**\n",
        "#@markdown ```\n",
        "#@markdown A:6:CA:B:26:CB\n",
        "#@markdown C:1:N1:A:45:OG\n",
        "#@markdown ```\n",
        "#@markdown\n",
        "#@markdown **Notes:**\n",
        "#@markdown * Chain names match those in **Input Sequences**.\n",
        "#@markdown * Residue numbering starts at 1.\n",
        "#@markdown * Atom names must match standardized PDB/CIF naming conventions.\n",
        "#@markdown * Only canonical residues and CCD ligands are supported.\n",
        "#@markdown * Covalent restraints ensure atoms remain bonded during folding but do not enforce bond angles or torsions.\n",
        "\n",
        "covalent_restraints = '' #@param {type:\"string\"}\n",
        "#@markdown - Specify covalent bonds between atoms. See above instructions for more details.\n",
        "\n",
        "# Process covalent restraints\n",
        "covalent_bonds = []\n",
        "if covalent_restraints.strip():\n",
        "    for line in covalent_restraints.strip().split('\\n'):\n",
        "        if line.strip():\n",
        "            parts = line.strip().split(':')\n",
        "            if len(parts) == 6:\n",
        "                chain1, res1, atom1, chain2, res2, atom2 = parts\n",
        "                covalent_bonds.append({\n",
        "                    'atom1': [chain1.strip(), int(res1.strip()), atom1.strip()],\n",
        "                    'atom2': [chain2.strip(), int(res2.strip()), atom2.strip()]\n",
        "                })\n",
        "            else:\n",
        "                print(f\"Invalid covalent restraint format: {line}\")\n",
        "\n",
        "print(f\"Covalent restraints configured: {len(covalent_bonds)} bonds\")\n",
        "for bond in covalent_bonds:\n",
        "    print(f\"  {bond['atom1'][0]}:{bond['atom1'][1]}:{bond['atom1'][2]} - {bond['atom2'][0]}:{bond['atom2'][1]}:{bond['atom2'][2]}\")\n",
        "\n",
        "if 'global_settings' in globals() and covalent_bonds:\n",
        "    global_settings['covalent_bonds'] = covalent_bonds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfaAZLH1-6M6",
        "outputId": "4300b2b0-ff86-4020-9e53-87be9782699e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìç Checking GPU availability...\n",
            "‚úÖ GPU: NVIDIA A100-SXM4-40GB (42.5 GB)\n",
            "\n",
            "üîß Kernel mode: --no_kernels\n",
            "   (Using CPU fallback - slower but more compatible)\n",
            "\n",
            "üîÑ Converting manual input to job format...\n",
            "   ‚úì Converted 2 sequence entries\n",
            "‚úÖ Job configuration complete\n",
            "‚úÖ Found existing folder: Boltz2_Predictions\n",
            "\n",
            "============================================================\n",
            "üöÄ STARTING PREDICTION\n",
            "============================================================\n",
            "Job: Cf4AVR4-single_791fc\n",
            "Sequences: 2\n",
            "============================================================\n",
            "üìù Generated YAML configuration\n",
            "üîß Command: boltz predict Cf4AVR4-single_791fc/Cf4AVR4-single_791fc.yaml --out_dir Cf4AVR4-single_791fc --recycling_steps 6 --sampling_steps 200 --diffusion_samples 5 --max_parallel_samples 5 --step_scale 1.638 --output_format mmcif --max_msa_seqs 8192 --override --no_kernels --use_msa_server --msa_server_url https://api.colabfold.com --msa_pairing_strategy greedy --write_full_pae --use_potentials\n"
          ]
        }
      ],
      "source": [
        "#@title Run Boltz-2 Prediction (Complete Integration)\n",
        "%%time\n",
        "import subprocess\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# COMPLETE INTEGRATION OF ALL CONFIGURATION CELLS\n",
        "\n",
        "# Check if global_settings exists\n",
        "if 'global_settings' not in globals():\n",
        "    print(\"‚ùå Error: Please run Cell 2 (Manual Input Configuration) first\")\n",
        "elif not global_settings.get('sequences'):\n",
        "    print(\"‚ùå Error: No sequences configured in Cell 2\")\n",
        "    print(\"   Please configure at least one sequence before running prediction\")\n",
        "else:\n",
        "    settings = global_settings\n",
        "\n",
        "    # GPU verification - EXACT FROM CSV\n",
        "    print(\"üìç Checking GPU availability...\")\n",
        "    try:\n",
        "        import torch\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)} ({torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB)\")\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è  WARNING: No GPU detected - predictions will be very slow\")\n",
        "    except ImportError:\n",
        "        print(\"‚ùå PyTorch not available\")\n",
        "\n",
        "    # Check kernel test status - EXACT FROM CSV\n",
        "    if not settings.get('kernels_tested', False):\n",
        "        print(\"\\n‚ö†Ô∏è  WARNING: Kernel preflight test not run!\")\n",
        "        print(\"   Running with --no_kernels by default for safety\")\n",
        "        settings['use_no_kernels'] = True\n",
        "\n",
        "    use_no_kernels_flag = settings.get('use_no_kernels', True)\n",
        "    print(f\"\\nüîß Kernel mode: {'--no_kernels' if use_no_kernels_flag else 'WITH kernels'}\")\n",
        "\n",
        "    if use_no_kernels_flag:\n",
        "        print(\"   (Using CPU fallback - slower but more compatible)\")\n",
        "    else:\n",
        "        print(\"   (Using CUDA kernels - faster performance)\")\n",
        "\n",
        "    # Helper functions - EXACT FROM CSV\n",
        "    def find_or_create_folder(drive, folder_name, parent_id='root'):\n",
        "        if not drive:\n",
        "            return None\n",
        "        try:\n",
        "            file_list = drive.ListFile({\n",
        "                'q': f\"title='{folder_name}' and '{parent_id}' in parents and mimeType='application/vnd.google-apps.folder' and trashed=false\"\n",
        "            }).GetList()\n",
        "            if file_list:\n",
        "                print(f\"‚úÖ Found existing folder: {folder_name}\")\n",
        "                return file_list[0]['id']\n",
        "            else:\n",
        "                folder = drive.CreateFile({\n",
        "                    'title': folder_name,\n",
        "                    'mimeType': 'application/vnd.google-apps.folder',\n",
        "                    'parents': [{'id': parent_id}]\n",
        "                })\n",
        "                folder.Upload()\n",
        "                print(f\"‚úÖ Created new folder: {folder_name}\")\n",
        "                return folder['id']\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Error with folder: {e}\")\n",
        "            return None\n",
        "\n",
        "    def upload_to_drive(drive, local_path, folder_id):\n",
        "        if not drive or not folder_id:\n",
        "            return None\n",
        "        try:\n",
        "            file = drive.CreateFile({\n",
        "                'title': os.path.basename(local_path),\n",
        "                'parents': [{'id': folder_id}]\n",
        "            })\n",
        "            file.SetContentFile(local_path)\n",
        "            file.Upload()\n",
        "            return file['alternateLink']\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Upload failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    # EXACT _generate_yaml from CSV BoltzJobProcessor\n",
        "    def _generate_yaml(job):\n",
        "        \"\"\"Generate YAML format for Boltz-2 - EXACT COPY FROM CSV PROCESSOR\"\"\"\n",
        "        lines = [\"version: 1\", \"sequences:\"]\n",
        "\n",
        "        # Group sequences by type and content\n",
        "        protein_groups = {}\n",
        "        dna_groups = {}\n",
        "        rna_groups = {}\n",
        "        ligand_groups = {}\n",
        "\n",
        "        for seq in job['sequences']:\n",
        "            seq_type = seq['type']\n",
        "\n",
        "            if seq_type == 'protein':\n",
        "                key = (seq['sequence'], tuple(sorted((m['position'], m['ccd']) for m in seq['modifications'])) if seq['modifications'] else ())\n",
        "                if key not in protein_groups:\n",
        "                    protein_groups[key] = []\n",
        "                protein_groups[key].append(seq)\n",
        "\n",
        "            elif seq_type == 'dna':\n",
        "                key = (seq['sequence'], tuple(sorted((m['position'], m['ccd']) for m in seq['modifications'])) if seq['modifications'] else ())\n",
        "                if key not in dna_groups:\n",
        "                    dna_groups[key] = []\n",
        "                dna_groups[key].append(seq)\n",
        "\n",
        "            elif seq_type == 'rna':\n",
        "                key = (seq['sequence'], tuple(sorted((m['position'], m['ccd']) for m in seq['modifications'])) if seq['modifications'] else ())\n",
        "                if key not in rna_groups:\n",
        "                    rna_groups[key] = []\n",
        "                rna_groups[key].append(seq)\n",
        "\n",
        "            elif seq_type == 'ligand':\n",
        "                if 'smiles' in seq:\n",
        "                    key = ('smiles', seq['smiles'])\n",
        "                else:\n",
        "                    key = ('ccd', seq['ccd'])\n",
        "                if key not in ligand_groups:\n",
        "                    ligand_groups[key] = []\n",
        "                ligand_groups[key].append(seq)\n",
        "\n",
        "        # Write protein sequences\n",
        "        for (sequence, mod_tuple), seqs in protein_groups.items():\n",
        "            lines.append(\"  - protein:\")\n",
        "            chain_ids = [s['id'] for s in seqs]\n",
        "            if len(chain_ids) == 1:\n",
        "                lines.append(f\"      id: {chain_ids[0]}\")\n",
        "            else:\n",
        "                lines.append(f\"      id: [{', '.join(chain_ids)}]\")\n",
        "            lines.append(f\"      sequence: {sequence}\")\n",
        "\n",
        "            if seqs[0]['modifications']:\n",
        "                lines.append(\"      modifications:\")\n",
        "                for mod in seqs[0]['modifications']:\n",
        "                    lines.append(f\"        - ptmType: {mod['ccd']}\")\n",
        "                    lines.append(f\"          ptmPosition: {mod['position']}\")\n",
        "\n",
        "        # Write DNA sequences\n",
        "        for (sequence, mod_tuple), seqs in dna_groups.items():\n",
        "            lines.append(\"  - dna:\")\n",
        "            chain_ids = [s['id'] for s in seqs]\n",
        "            if len(chain_ids) == 1:\n",
        "                lines.append(f\"      id: {chain_ids[0]}\")\n",
        "            else:\n",
        "                lines.append(f\"      id: [{', '.join(chain_ids)}]\")\n",
        "            lines.append(f\"      sequence: {sequence}\")\n",
        "\n",
        "            if seqs[0]['modifications']:\n",
        "                lines.append(\"      modifications:\")\n",
        "                for mod in seqs[0]['modifications']:\n",
        "                    lines.append(f\"        - modificationType: {mod['ccd']}\")\n",
        "                    lines.append(f\"          basePosition: {mod['position']}\")\n",
        "\n",
        "        # Write RNA sequences\n",
        "        for (sequence, mod_tuple), seqs in rna_groups.items():\n",
        "            lines.append(\"  - rna:\")\n",
        "            chain_ids = [s['id'] for s in seqs]\n",
        "            if len(chain_ids) == 1:\n",
        "                lines.append(f\"      id: {chain_ids[0]}\")\n",
        "            else:\n",
        "                lines.append(f\"      id: [{', '.join(chain_ids)}]\")\n",
        "            lines.append(f\"      sequence: {sequence}\")\n",
        "\n",
        "            if seqs[0]['modifications']:\n",
        "                lines.append(\"      modifications:\")\n",
        "                for mod in seqs[0]['modifications']:\n",
        "                    lines.append(f\"        - modificationType: {mod['ccd']}\")\n",
        "                    lines.append(f\"          basePosition: {mod['position']}\")\n",
        "\n",
        "        # Write ligand sequences\n",
        "        for (lig_type, lig_value), seqs in ligand_groups.items():\n",
        "            lines.append(\"  - ligand:\")\n",
        "            chain_ids = [s['id'] for s in seqs]\n",
        "            if len(chain_ids) == 1:\n",
        "                lines.append(f\"      id: {chain_ids[0]}\")\n",
        "            else:\n",
        "                lines.append(f\"      id: [{', '.join(chain_ids)}]\")\n",
        "\n",
        "            if lig_type == 'smiles':\n",
        "                lines.append(f\"      smiles: '{lig_value}'\")\n",
        "            else:\n",
        "                lines.append(f\"      ccd: {lig_value}\")\n",
        "\n",
        "        # Add constraints if present\n",
        "        if 'pocket' in job and job['pocket']:\n",
        "            lines.append(\"constraints:\")\n",
        "            lines.append(\"  pocket:\")\n",
        "            lines.append(f\"    binder: {job['pocket']['binder']}\")\n",
        "            lines.append(f\"    contacts: [{', '.join(map(str, job['pocket']['contacts']))}]\")\n",
        "\n",
        "        if 'covalent_bonds' in job and job['covalent_bonds']:\n",
        "            if 'pocket' not in job or not job['pocket']:\n",
        "                lines.append(\"constraints:\")\n",
        "            lines.append(\"  covalent:\")\n",
        "            for bond in job['covalent_bonds']:\n",
        "                lines.append(f\"    - atom1: [{bond['atom1'][0]}, {bond['atom1'][1]}, {bond['atom1'][2]}]\")\n",
        "                lines.append(f\"      atom2: [{bond['atom2'][0]}, {bond['atom2'][1]}, {bond['atom2'][2]}]\")\n",
        "\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    # STEP 1: Convert manual sequences to CSV processor format\n",
        "    print(\"\\nüîÑ Converting manual input to job format...\")\n",
        "\n",
        "    csv_sequences = []\n",
        "\n",
        "    # STEP 2: Get modifications from Cell 4.1 if present\n",
        "    modifications_by_seq = {}\n",
        "    if settings.get('modifications_list'):\n",
        "        print(f\"   ‚úì Found {len(settings['modifications_list'])} modifications from Cell 4.1\")\n",
        "        for mod in settings['modifications_list']:\n",
        "            seq_id = mod['seq_id']\n",
        "            if seq_id not in modifications_by_seq:\n",
        "                modifications_by_seq[seq_id] = []\n",
        "            # Convert format: {'seq_id': 'A', 'residue': 10, 'ccd': 'SEP'}\n",
        "            # to {'position': 10, 'ccd': 'SEP'}\n",
        "            modifications_by_seq[seq_id].append({\n",
        "                'position': mod['residue'],\n",
        "                'ccd': mod['ccd']\n",
        "            })\n",
        "\n",
        "    # Convert each sequence with modifications attached\n",
        "    for seq in settings['sequences']:\n",
        "        for chain_id in seq.get('chain_ids', [seq['name']]):\n",
        "            # Get modifications for this chain\n",
        "            mods = modifications_by_seq.get(chain_id, [])\n",
        "\n",
        "            seq_dict = {\n",
        "                'type': seq['type'],\n",
        "                'id': chain_id,\n",
        "                'modifications': mods if mods else []\n",
        "            }\n",
        "\n",
        "            # Handle different sequence types\n",
        "            if seq['type'] in ['protein', 'dna', 'rna']:\n",
        "                seq_dict['sequence'] = seq['content']\n",
        "            elif seq['type'] == 'smiles':\n",
        "                seq_dict['type'] = 'ligand'\n",
        "                seq_dict['smiles'] = seq['content']\n",
        "            elif seq['type'] == 'ccd':\n",
        "                seq_dict['type'] = 'ligand'\n",
        "                seq_dict['ccd'] = seq['content']\n",
        "\n",
        "            csv_sequences.append(seq_dict)\n",
        "\n",
        "    print(f\"   ‚úì Converted {len(csv_sequences)} sequence entries\")\n",
        "\n",
        "    # STEP 3: Convert pocket restraints from Cell 4.2 if present\n",
        "    pocket_config = None\n",
        "    if settings.get('binder_chain') and settings.get('pocket_contacts'):\n",
        "        print(f\"   ‚úì Found pocket restraints from Cell 4.2\")\n",
        "        # Convert from: {'chain_id': 'A', 'residue': 66} to just [66]\n",
        "        contacts = [c['residue'] for c in settings['pocket_contacts']]\n",
        "        pocket_config = {\n",
        "            'binder': settings['binder_chain'],\n",
        "            'contacts': contacts\n",
        "        }\n",
        "        print(f\"     Binder: {pocket_config['binder']}, Contacts: {contacts}\")\n",
        "\n",
        "    # STEP 4: Get covalent bonds from Cell 4.3 (already in correct format)\n",
        "    covalent_config = settings.get('covalent_bonds')\n",
        "    if covalent_config:\n",
        "        print(f\"   ‚úì Found {len(covalent_config)} covalent bonds from Cell 4.3\")\n",
        "\n",
        "    # Create job structure in CSV format\n",
        "    job = {\n",
        "        'name': settings['final_jobname'],\n",
        "        'sequences': csv_sequences,\n",
        "        'pocket': pocket_config,\n",
        "        'covalent_bonds': covalent_config\n",
        "    }\n",
        "\n",
        "    print(\"‚úÖ Job configuration complete\")\n",
        "\n",
        "    # Setup Google Drive folder if configured - EXACT FROM CSV\n",
        "    folder_id = None\n",
        "    if settings.get('drive'):\n",
        "        folder_id = find_or_create_folder(\n",
        "            settings['drive'],\n",
        "            settings.get('gdrive_folder_name', 'Boltz2_Predictions')\n",
        "        )\n",
        "\n",
        "    # SINGLE JOB PROCESSING - EXACT LOGIC FROM CSV LOOP\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"üöÄ STARTING PREDICTION\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Job: {job['name']}\")\n",
        "    print(f\"Sequences: {len(job['sequences'])}\")\n",
        "    if job['pocket']:\n",
        "        print(f\"Pocket restraints: {len(job['pocket']['contacts'])} contacts\")\n",
        "    if job['covalent_bonds']:\n",
        "        print(f\"Covalent bonds: {len(job['covalent_bonds'])} bonds\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    job_name = job['name']\n",
        "    job_dir = job_name\n",
        "    os.makedirs(job_dir, exist_ok=True)\n",
        "\n",
        "    # Generate YAML file - EXACT FROM CSV\n",
        "    yaml_content = _generate_yaml(job)\n",
        "    yaml_file = os.path.join(job_dir, f\"{job_name}.yaml\")\n",
        "\n",
        "    with open(yaml_file, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"üìù Generated YAML configuration\")\n",
        "\n",
        "    # Build Boltz command - EXACT FROM CSV LINE FOR LINE\n",
        "    cmd_parts = [\n",
        "        \"boltz\", \"predict\", yaml_file,\n",
        "        \"--out_dir\", job_dir,\n",
        "        \"--recycling_steps\", str(settings.get('recycling_steps', 6)),\n",
        "        \"--sampling_steps\", str(settings.get('sampling_steps', 200)),\n",
        "        \"--diffusion_samples\", str(settings.get('diffusion_samples', 5)),\n",
        "        \"--max_parallel_samples\", str(settings.get('max_parallel_samples', 5)),\n",
        "        \"--step_scale\", str(settings.get('step_scale', 1.638)),\n",
        "        \"--output_format\", settings.get('output_format', 'mmcif'),\n",
        "        \"--max_msa_seqs\", str(settings.get('max_msa_seqs', 8192)),\n",
        "        \"--override\"\n",
        "    ]\n",
        "\n",
        "    # Conditionally add --no_kernels based on preflight test - EXACT FROM CSV\n",
        "    if settings.get('use_no_kernels', True):\n",
        "        cmd_parts.append(\"--no_kernels\")\n",
        "\n",
        "    # Add MSA server if configured - EXACT FROM CSV\n",
        "    if settings.get('use_msa_server', True):\n",
        "        cmd_parts.extend([\n",
        "            \"--use_msa_server\",\n",
        "            \"--msa_server_url\", settings.get('msa_server_url', 'https://api.colabfold.com'),\n",
        "            \"--msa_pairing_strategy\", settings.get('msa_pairing_strategy', 'greedy')\n",
        "        ])\n",
        "\n",
        "    # Add optional flags - EXACT FROM CSV\n",
        "    if settings.get('write_full_pae', False):\n",
        "        cmd_parts.append(\"--write_full_pae\")\n",
        "    if settings.get('write_full_pde', False):\n",
        "        cmd_parts.append(\"--write_full_pde\")\n",
        "    if settings.get('use_potentials', True):\n",
        "        cmd_parts.append(\"--use_potentials\")\n",
        "    if settings.get('predict_affinity', False):\n",
        "        cmd_parts.extend([\n",
        "            \"--predict_affinity\",\n",
        "            \"--sampling_steps_affinity\", str(settings.get('sampling_steps_affinity', 200)),\n",
        "            \"--diffusion_samples_affinity\", str(settings.get('diffusion_samples_affinity', 5))\n",
        "        ])\n",
        "        if settings.get('affinity_mw_correction', False):\n",
        "            cmd_parts.append(\"--affinity_mw_correction\")\n",
        "\n",
        "    cmd = \" \".join(cmd_parts)\n",
        "    print(f\"üîß Command: {cmd}\")\n",
        "\n",
        "    # Run prediction - EXACT FROM CSV\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            cmd,\n",
        "            shell=True,\n",
        "            capture_output=True,\n",
        "            text=True,\n",
        "            timeout=7200  # 2 hour timeout\n",
        "        )\n",
        "\n",
        "        # CRITICAL: Always show stderr if present - EXACT FROM CSV\n",
        "        if result.stderr and result.stderr.strip():\n",
        "            print(f\"\\nüìã Boltz output/warnings:\")\n",
        "            stderr_lines = result.stderr.strip().split('\\n')\n",
        "            for line in stderr_lines[-50:]:\n",
        "                if line.strip():\n",
        "                    print(f\"   {line}\")\n",
        "\n",
        "        if result.returncode == 0:\n",
        "            # Check for output files - EXACT FROM CSV\n",
        "            results_dirs = [d for d in os.listdir(job_dir) if d.startswith('boltz_results_')]\n",
        "\n",
        "            if not results_dirs:\n",
        "                print(f\"\\n‚ùå No results directory found\")\n",
        "                print(f\"   Expected directory starting with 'boltz_results_' in {job_dir}\")\n",
        "                print(f\"   Actual contents: {os.listdir(job_dir)}\")\n",
        "            else:\n",
        "                predictions_dir = os.path.join(job_dir, results_dirs[0])\n",
        "\n",
        "                # Count structure files - EXACT FROM CSV\n",
        "                structure_count = 0\n",
        "                structure_files = []\n",
        "                for root, dirs, files in os.walk(predictions_dir):\n",
        "                    for file in files:\n",
        "                        if file.endswith(('.cif', '.pdb', '.mmcif')):\n",
        "                            structure_files.append(file)\n",
        "                            structure_count += 1\n",
        "\n",
        "                if structure_count > 0:\n",
        "                    print(f\"‚úÖ Generated {structure_count} structure files\")\n",
        "                    for f in structure_files:\n",
        "                        print(f\"   üìÑ {f}\")\n",
        "\n",
        "                    # Create results zip - EXACT FROM CSV\n",
        "                    zip_filename = f\"{job_name}_results.zip\"\n",
        "                    with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "                        for root, dirs, files in os.walk(job_dir):\n",
        "                            for file in files:\n",
        "                                file_path = os.path.join(root, file)\n",
        "                                arcname = os.path.relpath(file_path, job_dir)\n",
        "                                zipf.write(file_path, arcname)\n",
        "\n",
        "                    print(f\"üì¶ Created: {zip_filename}\")\n",
        "\n",
        "                    # Google Drive upload - EXACT FROM CSV\n",
        "                    if folder_id:\n",
        "                        try:\n",
        "                            url = upload_to_drive(settings['drive'], zip_filename, folder_id)\n",
        "                            if url:\n",
        "                                print(f\"  ‚òÅÔ∏è  Uploaded to Google Drive: {url}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"‚ö†Ô∏è  Google Drive upload failed: {e}\")\n",
        "\n",
        "                    elapsed = time.time() - start_time\n",
        "                    print(f\"‚è±Ô∏è  Completed in {elapsed:.1f}s\")\n",
        "                else:\n",
        "                    print(\"‚ùå No structure files found in output\")\n",
        "\n",
        "        else:\n",
        "            print(f\"\\n‚ùå Prediction failed (return code: {result.returncode})\")\n",
        "            if result.stderr:\n",
        "                print(\"Error output:\")\n",
        "                print(result.stderr[-1000:])\n",
        "\n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚ùå Prediction timed out after 2 hours\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Unexpected error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ PREDICTION COMPLETE\")\n",
        "    print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNQRQyuS6jmwQi/NE0h0Tj+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}